{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNLZLq0qMejAg53QSlMsIsv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Machforo/emotional_project/blob/main/emotional_detection_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iizgyO0NBQf4"
      },
      "outputs": [],
      "source": [
        "# emotion detection \n",
        "# start from here"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#############################################\n",
        "#TASK 1\n",
        "###########################################"
      ],
      "metadata": {
        "id": "ybCptiDYVWOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Connecting to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfE_BvWBVjN2",
        "outputId": "f3a143aa-0ee8-4cc7-cc7e-c1153e376fa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing necessary packages\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout,Dense,Activation,Flatten,BatchNormalization\n",
        "from keras.layers import Conv2D,MaxPooling2D\n",
        "import os\n"
      ],
      "metadata": {
        "id": "u9eDH3Z3WM8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#no. of classes\n",
        "no_c=8\n",
        "# batch size\n",
        "'''\n",
        "This variable defines the batch size.The batch size is a number of samples processed before the model is updated. The number of epochs is the number of complete passes through the training dataset. The size of a batch must be more than or equal to one and less than or equal to the number of samples in the training dataset.\n",
        "'''\n",
        "batch_size=32\n",
        "img_rows,img_col=50,50"
      ],
      "metadata": {
        "id": "cZpwMVLKW6ox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###########################\n",
        "#Task 2\n",
        "##############################"
      ],
      "metadata": {
        "id": "_69InJk3XZen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_dir='/content/drive/MyDrive/emotion project'\n"
      ],
      "metadata": {
        "id": "joQ9TtRRXiom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking image format\n",
        "from keras import backend as K\n",
        "if(K.image_data_format=='channels_first'):\n",
        "  input_shape=(3,img_rows,img_col)\n",
        "else:\n",
        "  input_shape=(img_rows,img_col,3)  "
      ],
      "metadata": {
        "id": "WdyOCLtcZU8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image augmentation techniques\n",
        "datagen_train=ImageDataGenerator(rescale=1./255,\n",
        "                                 rotation_range=30,\n",
        "                                 shear_range=0.4,\n",
        "                                 zoom_range=0.3,\n",
        "                                 width_shift_range=0.4,\n",
        "                                 height_shift_range=0.3,\n",
        "                                 horizontal_flip=True,\n",
        "                                 fill_mode='nearest',\n",
        "                                 validation_split=0.2\n",
        "                                 )\n",
        "#training data =80% validation data=20%\n",
        "\n",
        "train_generator=datagen_train.flow_from_directory(train_data_dir,\n",
        "                                                  subset='training',\n",
        "                                                  color_mode='grayscale',\n",
        "                                                  target_size=(img_rows,img_col),\n",
        "                                                  batch_size=batch_size,\n",
        "                                                  class_mode='categorical',\n",
        "                                                  shuffle=True)\n",
        "\n",
        "validation_generator=datagen_train.flow_from_directory(train_data_dir,\n",
        "                                                  subset='validation',\n",
        "                                                  color_mode='grayscale',\n",
        "                                                  target_size=(img_rows,img_col),\n",
        "                                                  batch_size=batch_size,\n",
        "                                                  class_mode='categorical',\n",
        "                                                  shuffle=True)\n",
        "\n",
        "'''\n",
        "directory: The directory of the dataset.\n",
        "color_mode: Here i am converting the images to gray-scale as i am not interested in the color of the images but only the expressions.\n",
        "target_size: Convert the images to a uniform size.\n",
        "batch_size: To make baches of data to train.\n",
        "class_mode: Here i am using ‘categorical’ as the class mode as i am categorizing my images into 5 classes.\n",
        "shuffle: To shuffle the dataset for better training.\n",
        "'''"
      ],
      "metadata": {
        "id": "JicKgLH4Zw_J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "a01fc33c-65a0-4ce9-a727-10f51af293ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 252 images belonging to 8 classes.\n",
            "Found 59 images belonging to 8 classes.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndirectory: The directory of the dataset.\\ncolor_mode: Here i am converting the images to gray-scale as i am not interested in the color of the images but only the expressions.\\ntarget_size: Convert the images to a uniform size.\\nbatch_size: To make baches of data to train.\\nclass_mode: Here i am using ‘categorical’ as the class mode as i am categorizing my images into 5 classes.\\nshuffle: To shuffle the dataset for better training.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "################################\n",
        "#formulation of a cnn network\n",
        "###############################\n"
      ],
      "metadata": {
        "id": "K1gpOXe14NH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_2aY9SsP4jgb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}